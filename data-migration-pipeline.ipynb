{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c6f511-47f1-4c0f-9b89-3de6013be5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from data_pipeline_functions import get_load_params_from_json, load_to_spark, write_to_cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da28bac0-910e-4e31-b14d-eaec5c50cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a4f61f-9cc4-46ba-9d79-40fc409e2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries_mappings = \"table_models.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ee580d-ea77-47c4-b99b-ef329a9a573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'customer': {'table_name': 'customer', 'query': '(SELECT * FROM customer ) AS customer'}}\n"
     ]
    }
   ],
   "source": [
    "# get cassandra table and sql query mappings\n",
    "table_mappings = get_load_params_from_json(file_path=sql_queries_mappings)\n",
    "print(table_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426dc6d0-afc1-4f9f-8a7b-3dadc947472a",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5a76db-c58a-49c7-ae16-3a68bad9d050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.29.112.1\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "sock_name = socket.gethostname()\n",
    "host = socket.gethostbyname(sock_name)\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93d83fe-d490-456a-ba7e-2afe63ec5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf()\\\n",
    "    .setAll([\n",
    "        ('spark.executor.memory', '2g'), \n",
    "        ('spark.executor.cores', '2'), \n",
    "        ('spark.driver.host', host),\n",
    "        (\"spark.shuffle.service.enabled\", \"false\"),\n",
    "        (\"spark.dynamicAllocation.enabled\", \"false\"),\n",
    "        ('spark.cores.max', '2'), \n",
    "        ('spark.driver.memory','4g'),\n",
    "    ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4cdf8e-e333-496b-905c-e5980f303b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataMigration\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "                        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.1,org.postgresql:postgresql:42.2.18\")\\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1143a521-0484-487a-8262-553c46c1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSQL_SERVERNAME=\"127.0.0.1\"\n",
    "PSQL_PORT=5432\n",
    "PSQL_DBNAME=\"postgres\"\n",
    "PSQL_USERNAME=\"postgres\"\n",
    "PSQL_PASSWORD=\"mypassword\"\n",
    "KEYSPACE = \"archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f724f4a-9524-4e20-b19b-caab89a47173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_pipeline_functions:Successfully loaded data from postgres into spark.\n",
      "INFO:data_pipeline_functions:Data written successfully from customer into keyspace archive.\n"
     ]
    }
   ],
   "source": [
    "for cassandra_table, table_details in table_mappings.items():\n",
    "    postgres_table = table_details['table_name']\n",
    "    query = table_details['query']\n",
    "    \n",
    "    df = load_to_spark(\n",
    "    spark=spark,\n",
    "    sql_query=query,\n",
    "    psql_server=PSQL_SERVERNAME,\n",
    "    psql_dbname=PSQL_DBNAME,\n",
    "    psql_port=PSQL_PORT,\n",
    "    psql_username=PSQL_USERNAME,\n",
    "    psql_password=PSQL_PASSWORD\n",
    "    )\n",
    "    \n",
    "    write_to_cassandra(\n",
    "        df=df,\n",
    "        cassandra_table=cassandra_table,\n",
    "        postgres_table=postgres_table,\n",
    "        keyspace=KEYSPACE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
